{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 122519208,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "CIFAR10",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyeeee/CIFAR10-Classification/blob/main/CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "fareselmenshawii_cats_vs_dogs_classification_path = kagglehub.notebook_output_download('fareselmenshawii/cats-vs-dogs-classification')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "yjAok2TZkUJt"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# # For example, here's several helpful packages to load\n",
        "\n",
        "# import numpy as np # linear algebra\n",
        "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# # Input data files are available in the read-only \"../input/\" directory\n",
        "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-17T18:19:26.95221Z",
          "iopub.execute_input": "2025-03-17T18:19:26.952607Z",
          "iopub.status.idle": "2025-03-17T18:19:26.957097Z",
          "shell.execute_reply.started": "2025-03-17T18:19:26.952544Z",
          "shell.execute_reply": "2025-03-17T18:19:26.955696Z"
        },
        "id": "7PrmX6TckUJu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import the required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T06:25:57.789738Z",
          "iopub.execute_input": "2025-03-18T06:25:57.789925Z",
          "iopub.status.idle": "2025-03-18T06:26:04.750966Z",
          "shell.execute_reply.started": "2025-03-18T06:25:57.789906Z",
          "shell.execute_reply": "2025-03-18T06:26:04.750314Z"
        },
        "id": "BR6wlMjikUJv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T06:27:33.108258Z",
          "iopub.execute_input": "2025-03-18T06:27:33.108547Z",
          "iopub.status.idle": "2025-03-18T06:27:33.180922Z",
          "shell.execute_reply.started": "2025-03-18T06:27:33.108526Z",
          "shell.execute_reply": "2025-03-18T06:27:33.180238Z"
        },
        "id": "NBGmw8ytkUJv",
        "outputId": "f13bfb5e-f353-4667-ede8-0f4d6777c6cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "num_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T06:27:38.15086Z",
          "iopub.execute_input": "2025-03-18T06:27:38.151179Z",
          "iopub.status.idle": "2025-03-18T06:27:38.154898Z",
          "shell.execute_reply.started": "2025-03-18T06:27:38.151156Z",
          "shell.execute_reply": "2025-03-18T06:27:38.153936Z"
        },
        "id": "DdA1aiobkUJw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset has PILImages images of range [0,1].\n",
        "# We transform them to Tensors of normalized range [-1,1]\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
        "train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False)\n",
        "\n",
        "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T06:27:41.84148Z",
          "iopub.execute_input": "2025-03-18T06:27:41.841801Z",
          "iopub.status.idle": "2025-03-18T06:27:48.938251Z",
          "shell.execute_reply.started": "2025-03-18T06:27:41.841773Z",
          "shell.execute_reply": "2025-03-18T06:27:48.937592Z"
        },
        "id": "bG_X0X8OkUJx",
        "outputId": "a8b65c4a-2175-4767-87b0-240fd80ff160"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 170M/170M [00:03<00:00, 45.0MB/s] \n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement convolution net\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet,self).__init__()\n",
        "        self.conv1=nn.Conv2d(3,6,5) #input channel size is 3, 32*32--->28*28\n",
        "        self.pool = nn.MaxPool2d(2,2) # kernel size is 2 and strides is 2, 14*14\n",
        "        self.conv2=nn.Conv2d(6,16,5) # 10*10\n",
        "        # Another pooling operation, 5*5\n",
        "        self.fc1=nn.Linear(16*5*5, 120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3=nn.Linear(84,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.pool(F.relu(self.conv1(x)))\n",
        "        x=self.pool(F.relu(self.conv2(x)))\n",
        "        x=x.view(-1,16*5*5) # Tensor flattened\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=self.fc3(x)\n",
        "        return x\n",
        "        # No softmax, since it has been already included in the CrossEntropy loss handling."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T06:27:53.121619Z",
          "iopub.execute_input": "2025-03-18T06:27:53.121909Z",
          "iopub.status.idle": "2025-03-18T06:27:53.128235Z",
          "shell.execute_reply.started": "2025-03-18T06:27:53.121886Z",
          "shell.execute_reply": "2025-03-18T06:27:53.127293Z"
        },
        "id": "13EHxqznkUJx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop and parameters settings\n",
        "model = ConvNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "n_total_steps =len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i,(images,labels) in enumerate(train_loader):\n",
        "        # origin shape: [4,3,32,32] = 4,3,1024, 32x32 pixels\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs,labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if(i+1) % 2000 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T06:31:03.918869Z",
          "iopub.execute_input": "2025-03-18T06:31:03.9192Z",
          "iopub.status.idle": "2025-03-18T06:33:36.683591Z",
          "shell.execute_reply.started": "2025-03-18T06:31:03.919178Z",
          "shell.execute_reply": "2025-03-18T06:33:36.682828Z"
        },
        "id": "a7CCW-NQkUJy",
        "outputId": "6e21b646-7f27-464b-d6d1-03cc256f6008"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch [1/4], Step [2000/12500], Loss: 1.8610\nEpoch [1/4], Step [4000/12500], Loss: 1.0515\nEpoch [1/4], Step [6000/12500], Loss: 0.8775\nEpoch [1/4], Step [8000/12500], Loss: 1.6788\nEpoch [1/4], Step [10000/12500], Loss: 1.8057\nEpoch [1/4], Step [12000/12500], Loss: 2.1051\nEpoch [2/4], Step [2000/12500], Loss: 1.3111\nEpoch [2/4], Step [4000/12500], Loss: 1.0797\nEpoch [2/4], Step [6000/12500], Loss: 2.2683\nEpoch [2/4], Step [8000/12500], Loss: 1.1496\nEpoch [2/4], Step [10000/12500], Loss: 0.9495\nEpoch [2/4], Step [12000/12500], Loss: 0.9925\nEpoch [3/4], Step [2000/12500], Loss: 1.4591\nEpoch [3/4], Step [4000/12500], Loss: 0.6501\nEpoch [3/4], Step [6000/12500], Loss: 1.2725\nEpoch [3/4], Step [8000/12500], Loss: 0.7467\nEpoch [3/4], Step [10000/12500], Loss: 1.0616\nEpoch [3/4], Step [12000/12500], Loss: 0.8339\nEpoch [4/4], Step [2000/12500], Loss: 2.0478\nEpoch [4/4], Step [4000/12500], Loss: 1.0457\nEpoch [4/4], Step [6000/12500], Loss: 1.4507\nEpoch [4/4], Step [8000/12500], Loss: 2.8334\nEpoch [4/4], Step [10000/12500], Loss: 1.8622\nEpoch [4/4], Step [12000/12500], Loss: 1.7609\nFinished Training\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "with torch.no_grad(): #implies no backward propagation\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value,index)\n",
        "        _, predicted = torch.max(outputs,1) # torch.max(outputs,1) returns two values, the confidence value or the max score and the index of the confidence score\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if(label == pred):\n",
        "                n_class_correct[label] +=1\n",
        "            n_class_samples[label] +=1\n",
        "    acc = 100.0*n_correct/n_samples\n",
        "    print(f'Accuracy of the network: {acc}%')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0*n_class_correct[i]/n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}:{acc}%')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-18T06:33:46.805239Z",
          "iopub.execute_input": "2025-03-18T06:33:46.805513Z",
          "iopub.status.idle": "2025-03-18T06:33:51.756517Z",
          "shell.execute_reply.started": "2025-03-18T06:33:46.805491Z",
          "shell.execute_reply": "2025-03-18T06:33:51.755736Z"
        },
        "id": "PnZCNvlDkUJy",
        "outputId": "09de952b-70d8-4a49-a035-1eb708f0c8e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy of the network: 55.58%\nAccuracy of plane:53.6%\nAccuracy of car:70.1%\nAccuracy of bird:46.7%\nAccuracy of cat:31.4%\nAccuracy of deer:50.1%\nAccuracy of dog:40.7%\nAccuracy of frog:57.1%\nAccuracy of horse:63.9%\nAccuracy of ship:79.4%\nAccuracy of truck:62.8%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}